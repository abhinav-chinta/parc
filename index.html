<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs">
  <meta property="og:title" content="Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs"/>
  <meta property="og:description" content="Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs"/>
  <meta property="og:url" content=""/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs">
  <meta name="twitter:description" content="Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Premise-Augmented Reasoning Chains, Math Reasoning, LLMs, Error Identification">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="static/js/jquery.min.js"></script>
  <script src="static/js/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              Premise-Augmented Reasoning Chains Improve Error Identification in Math Reasoning with LLMs
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://sagnikmukherjee.github.io/">Sagnik Mukherjee</a><sup>*,1</sup>,</span>
              <span class="author-block"><a href="https://abhinavchinta.com/">Abhinav Chinta</a><sup>*,1</sup>,</span>
              <span class="author-block"><a href="https://youngerous.github.io/">Takyoung Kim</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://www.linkedin.com/in/tarun-sharma-2a2923176/?originalSubdomain=in">Tarun Sharma</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://siebelschool.illinois.edu/about/people/all-faculty/dilek">Dilek Hakkani-Tur</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Illinois at Urbana Champaign</span>
              <span class="author-block"><sup>*</sup>Equal contribution</span>
            </div>

            <img alt="ConvAI Lab" src="static/images/convai-logo.png" style="width:10%" />

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://uiuc-conversational-ai-lab.github.io/" target="_blank">ConvAI Lab</a></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2502.02362" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.02362" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code & Data Link (merged). -->
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code & Data</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into Premise Augmented Reasoning Chains (PARC) by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely PERL (Premises and ERrors identification in LLMs), we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90% recall in premise identification. We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6% to 16% absolute when step-by-step verification is carried out in PARC under the premises. Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Main image -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <img src="static/images/parc_main.png" alt="PARC Main Image" class="publication-image">
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End main image -->

  <!-- Method section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-3">Method</h2>
            <div class="content has-text-justified">
              <p>
                Our framework, Premise-Augmented Reasoning Chains (PARC), is structured into three primary stages: Premise Extraction, Error Identification, and Accumulation Error Detection. Initially, PARC transforms conventional Linear Reasoning Chains (LRCs) by explicitly identifying premises necessary for each reasoning step. This transformation converts LRCs into a directed acyclic graph structure, improving the traceability and evaluation of the reasoning process.
              </p>
              
              <!-- Baseline vs PARC comparison image -->
              <div class="columns is-centered">
                <div class="column has-text-centered">
                  <img src="static/images/baseline_vs_parc.png" alt="Baseline vs PARC Example" class="publication-image">
                </div>
              </div>
              
              <h3 class="title is-4">Premise Extraction</h3>
              <p>
                The Premise Extraction component converts a Linear Reasoning Chain (LRC), comprising sequentially generated reasoning steps, into a Premise-Augmented Reasoning Chain (PARC). Each step in PARC explicitly links back to its necessary premises. We explore two distinct approaches for premise identification: Aggregative Premise Mapping and Dyadic Premise Mapping.
              </p>
              <p>
                In the Aggregative approach, we query large language models (LLMs) with the entire reasoning context up to the current step to collectively identify all necessary premises simultaneously. Conversely, the Dyadic approach performs a pairwise assessment, where an LLM evaluates the validity of each earlier step as a premise individually. Steps identified as necessary are aggregated into a premise set for the current step. This systematic identification of premises enhances context relevance and reduces distractors, facilitating improved verification accuracy.
              </p>
              
              <h3 class="title is-4">Error Identification</h3>
              <p>
                After premises are identified, we systematically evaluate each step for errors. The error identification process involves three primary error categories: Mathematical Errors, Logical Inconsistencies, and Accumulation Errors. Mathematical Errors refer to incorrect calculations or misapplication of formulas, while Logical Inconsistencies occur when a step does not logically follow from its premises. Our method prompts an LLM to evaluate mathematical correctness and logical consistency independently, constrained to the minimal context provided by identified premises.
              </p>
              
              <h3 class="title is-4">Accumulation Error Detection</h3>
              <p>
                Accumulation Errors are identified through a dependency graph traversal. Steps that are locally correct but depend on erroneous prior steps (premises) are flagged as accumulation errors. We employ Depth-First Search (DFS) on the PARC structure to systematically identify these dependencies, clearly distinguishing inherent step-level inaccuracies from errors propagated due to faulty premises.
              </p>
              
              <!-- Algorithm image -->
              <div class="columns is-centered">
                <div class="column has-text-centered">
                  <img src="static/images/algorithm.png" alt="Algorithm 1 Constructing and Evaluating PARC" class="publication-image">
                  <p class="caption">Algorithm 1: Constructing and Evaluating PARC</p>
                </div>
              </div>
              
              <h3 class="title is-4">Dataset and Evaluation Setup</h3>
              <p>
                We developed the Premises and ERrors identification in Language models (PERL) dataset to assess the capabilities of our approach. PERL incorporates reasoning chains from established mathematical reasoning datasets (GSM8K, MATH, Orca-Math, and MetaMathQA), annotated with both premises and error types using OpenAI's GPT-4o. This dataset includes naturally occurring errors as well as systematically introduced synthetic errors, ensuring comprehensive coverage of potential error scenarios.
              </p>
              <p>
                We evaluate PARC's effectiveness using precision, recall, F1-score for premise extraction, and accuracy metrics for error identification. Our experimental setup utilizes both open-source (e.g., Llama, Qwen) and proprietary (e.g., GPT-4o) large language models, comparing our premise-centric verification approach against traditional full-context baseline methods.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Method section -->

  <!-- Results section -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>

      <h3 class="title is-4">Performance</h3>
      <p>
        We evaluate the effectiveness of Premise-Augmented Reasoning Chains (PARC) in enhancing the error identification capabilities of large language models (LLMs) for mathematical reasoning. Evaluation focuses on two primary aspects: Premise Identification and Error Identification.
      </p>

      <h3 class="title is-4">Premise Identification</h3>
      <p>
        <b>Datasets:</b> The evaluation was conducted across four mathematical reasoning datasets: GSM8K, MATH, Orca Math, and MetaMathQA. These datasets contain diverse mathematical problems ranging from elementary to competition-level questions.
      </p>
      <p>
        <b>Baselines:</b> Premise identification was assessed under two methods—Aggregative Premise Mapping (identifying premises collectively) and Dyadic Premise Mapping (pairwise identification). Models evaluated include Llama 3.1 (8B and 70B parameters), Qwen 2.5 (7B and 32B parameters), and GPT-4 variants (GPT4o-mini and GPT-4o).
      </p>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="static/images/table1.png" alt="Table 1: Results for Premise Identification under Aggregative Premise Mapping">
          <p class="caption">
            Results for Premise Identification under Aggregative Premise Mapping show strong performance from larger models, especially Llama 3.1 70B, Qwen 2.5 32B, and GPT-4o, all achieving over 90% recall consistently across datasets. Notably, Aggregative mapping significantly outperformed Dyadic mapping, demonstrating higher precision and recall, suggesting that collective identification of premises is more effective and efficient for LLMs.
          </p>
        </div>
      </div>

      <h3 class="title is-4">Error Identification</h3>
      <p>
        <b>Datasets:</b> Error identification was tested using the PERL dataset (Premises and ERrors identification in LLMs), comprising correct solutions (positives), incorrect solutions (negatives), and synthetically generated negative examples to simulate realistic errors.
      </p>
      <p>
        <b>Baselines:</b> Error detection was compared across two primary contexts: Full Context (standard LLM inference over the entire reasoning chain) and Model Premises (reasoning verification using identified premises). Models included are Llama 3.1 (8B and 70B), Qwen 2.5 (7B, 32B, and 72B), GPT4o-mini, and GPT-4o.
      </p>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="static/images/table2.png" alt="Table 2: Comparative results between Aggregative and Dyadic Premise Mapping">
          <p class="caption">
            Comparison between Aggregative and Dyadic Premise Mapping methods, showing the superior performance of the Aggregative approach.
          </p>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="static/images/table3.png" alt="Table 3: Results of Error Identification across different models">
          <p class="caption">
            Results illustrate that the use of Model Premises substantially improves accuracy in error identification across all models, with larger models such as GPT-4o and Llama 3.1 70B benefiting the most. In particular, GPT-4o improved error identification accuracy from 68.52% in the Full Context baseline to 79.82% under Model Premises on the GSM8K dataset.
          </p>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="static/images/table4.png" alt="Table 4: Comparison of oracle versus model-generated premises">
          <p class="caption">
            Comparison of oracle versus model-generated premises demonstrates that error identification accuracy remains robust when LLM-generated premises are used, reflecting that current models achieve high-quality premise identification.
          </p>
        </div>
      </div>

      <h3 class="title is-4">Detailed Error Type Analysis</h3>
      
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="static/images/table5.png" alt="Table 5: Analysis of error types and detection accuracy">
          <p class="caption">
            Further analysis highlights challenges in detecting accumulation errors compared to native errors (mathematical and logical). Under Model Premises, identification accuracy significantly increased for both types, though accumulation errors remained the hardest to detect, improving from 12% (Full Context baseline) to approximately 57.54% (Model Premises).
          </p>
        </div>
      </div>

      <h3 class="title is-4">Summary</h3>
      <p>
        Our evaluations indicate that converting Linear Reasoning Chains to PARCs and verifying steps under identified premises significantly enhances the accuracy and reliability of error detection in LLMs. The results underscore the importance of premise-aware verification, particularly for detecting subtle accumulation errors that propagate through reasoning chains.
      </p>
    </div>
  </section>
  <!-- End Results section -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{mukherjee2025premiseaugmentedreasoningchainsimprove,
      title={Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs}, 
      author={Sagnik Mukherjee and Abhinav Chinta and Takyoung Kim and Tarun Anoop Sharma and Dilek Hakkani-Tür},
      year={2025},
      eprint={2502.02362},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.02362}, 
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
